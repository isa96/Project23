{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McCj1BZCTSg8"
      },
      "outputs": [],
      "source": [
        "import warnings;warnings.filterwarnings(\"ignore\") # to remove \"warning\" output\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "# Data Analyst & Linear Algebra\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "# Data Visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Image processing\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import skimage\n",
        "import skimage.io\n",
        "import skimage.transform\n",
        "from keras.preprocessing import image\n",
        "# ML\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.svm import SVC # Support Vector Machine\n",
        "from sklearn.tree import DecisionTreeClassifier # Decision Tree\n",
        "from sklearn.ensemble import RandomForestClassifier # Random Forest\n",
        "from sklearn.neighbors import KNeighborsClassifier # K-Nearest Neighbour\n",
        "from sklearn.linear_model import LogisticRegression # Logistic Regression \n",
        "# Deep Learning\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential # Create Layer\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D # Layer by Layer\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator # Image preprocessing\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "# Metrics Evaluation\n",
        "from sklearn.metrics import * # import all metrics evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2A90lxjy8_w"
      },
      "outputs": [],
      "source": [
        "# install library for split from a folder of datasets to  train,test,val folder\n",
        "!pip install split-folders tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpyawCvVzDgI"
      },
      "outputs": [],
      "source": [
        "# split folder\n",
        "import splitfolders\n",
        "splitfolders.ratio(\"/content/drive/MyDrive/data_img\", output=\"output\", seed=1337, ratio=(.7,0.3)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H8CSS0AgFxC"
      },
      "outputs": [],
      "source": [
        "# initialize path\n",
        "path,dir = \"/content/drive/MyDrive/data_img/\",\"/content/drive/MyDrive/data_img\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq5xBUIEkXge"
      },
      "outputs": [],
      "source": [
        "for dirname, _, filenames in os.walk(path):\n",
        "    for filename in filenames:\n",
        "        os.path.join(dirname, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnDMHkUtkmE5"
      },
      "outputs": [],
      "source": [
        "# get each file per label\n",
        "Blight = glob(os.path.join(dir+\"/Blight/\"+\"*\"))\n",
        "Common_Rust = glob(os.path.join(dir+\"/Common_Rust/\"+\"*\"))\n",
        "Gray_Leaf_Spot = glob(os.path.join(dir+\"/Gray_Leaf_Spot/\"+\"*\"))\n",
        "healthy = glob(os.path.join(dir+\"/Healthy/\"+\"*\"))\n",
        "print(\"Images with Blight, Common_Rust and Gray Leaf Spot are \\n\\t   \"+str(len(Blight))+\"  \\t\"+ str(len(Common_Rust))+\"\\t\\t\\t\"+str(len(Gray_Leaf_Spot)))\n",
        "print(\"Healthy Images are \\n   \" + str(len(healthy)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXKZb_0fevuw"
      },
      "outputs": [],
      "source": [
        "# convert image file into np.array & get label with same length as their length files\n",
        "blight_array = [np.array(Image.open(x)) for x in tqdm(Blight)]\n",
        "blight_label = [\"Blight\" for x in tqdm(Blight)]\n",
        "rust_array = [np.array(Image.open(x)) for x in tqdm(Common_Rust)]\n",
        "rust_label = [\"Common_Rust\" for x in tqdm(Common_Rust)]\n",
        "Gray_array = [np.array(Image.open(x)) for x in tqdm(Gray_Leaf_Spot)]\n",
        "Gray_label = [\"Gray_Leaf_Spot\" for x in tqdm(Gray_Leaf_Spot)]\n",
        "Health_array = [np.array(Image.open(x)) for x in tqdm(healthy)]\n",
        "Health_label = [\"Healthy\" for x in tqdm(healthy)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erdGfZHrfF2s"
      },
      "outputs": [],
      "source": [
        "# create dataframe for simple model ML\n",
        "df = pd.DataFrame({\"Path\":blight_array+rust_array+Gray_array+Health_array,\n",
        "                   \"Label\":blight_label+rust_label+Gray_label+Health_label})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM9bGVLsmTN2"
      },
      "outputs": [],
      "source": [
        "# change label from string to int\n",
        "df.Label = df.Label.replace({'Blight':2, 'Common_Rust':3, 'Gray_Leaf_Spot':4, 'Healthy':1}).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTX7JMFjn6xp"
      },
      "outputs": [],
      "source": [
        "# add filename per image\n",
        "blight_path = [x for x in os.listdir(dir+\"/Blight/\")]\n",
        "rust_path = [x for x in os.listdir(dir+\"/Common_Rust/\")]\n",
        "Gray_path = [x for x in os.listdir(dir+\"/Gray_Leaf_Spot/\")]\n",
        "Health_path = [x for x in os.listdir(dir+\"/Healthy/\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHoT_KBrmTQ2"
      },
      "outputs": [],
      "source": [
        "df[\"FileName\"] = blight_path+rust_path+Gray_path+Health_path\n",
        "df.Label = df.Label.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMno6pr4mTZL"
      },
      "outputs": [],
      "source": [
        "# prepare data, drop path columns... IMG_SIZE is x,y axis of image\n",
        "IMG_SIZE = 256\n",
        "data = df.drop(\"Path\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EynIoYexTluU"
      },
      "outputs": [],
      "source": [
        "train_datagen = image.ImageDataGenerator(rotation_range = 180,\n",
        "                                  width_shift_range = 0.1,\n",
        "                                  height_shift_range = 0.1,\n",
        "                                  brightness_range = [0.1,1.1],\n",
        "                                  horizontal_flip = True,\n",
        "                                  vertical_flip = True,\n",
        "                                  rescale = 1./255,\n",
        "                                  zoom_range = 0.5,\n",
        "                                  validation_split = 0.2)\n",
        "val_datagen = image.ImageDataGenerator(rescale=1./255,\n",
        "                                      validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M90tkSTCmTgB"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory(directory = \"/content/output/train\",\n",
        "                                                   target_size = (IMG_SIZE,IMG_SIZE),\n",
        "                                                   color_mode = \"rgb\",\n",
        "                                                   class_mode = \"categorical\",\n",
        "                                                   batch_size = 64,\n",
        "                                                   shuffle = True,)\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(directory = \"/content/output/train\",\n",
        "                                                   target_size = (IMG_SIZE,IMG_SIZE),\n",
        "                                                   color_mode = \"rgb\",\n",
        "                                                   class_mode = \"categorical\",\n",
        "                                                   batch_size = 64,\n",
        "                                                   shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j6sfJekvSQu"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding = 'Same',input_shape = [IMG_SIZE,IMG_SIZE,3]),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation = 'relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024,activation = 'relu'),\n",
        "    tf.keras.layers.Dense(4, activation = 'softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLp3CwySmTrF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop,Adam\n",
        "optimizer = Adam(lr = 0.001)\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = optimizer,\n",
        "             metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBb45JFimTuS"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl015zilmTyi"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJGxWPalmT11"
      },
      "outputs": [],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n",
        "                           patience = 5, mode = 'min', verbose = 1,\n",
        "                           restore_best_weights = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOM-O-YymT5A"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(train_generator,epochs = epochs,validation_data = val_generator,callbacks = early_stop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP7hZqxpabdv"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/LeNet_10.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy1Vux0jY7VH"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.grid(True)\n",
        "plt.legend(['train', 'val'], loc='upper left');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD_QOpIO4cjQ"
      },
      "source": [
        "## Simple Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdQ0xTAZmUAe"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import warnings\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import mahotas\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from random import randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_mkAdIFo-EZ"
      },
      "outputs": [],
      "source": [
        "!pip install mahotas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmNvF6zxmUK7"
      },
      "outputs": [],
      "source": [
        "# Hu Moments\n",
        "bins             = 8\n",
        "def fd_hu_moments(image):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
        "    return feature\n",
        "# Haralick Texture\n",
        "def fd_haralick(image):\n",
        "    # convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # compute the haralick texture feature vector\n",
        "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
        "    # return the result\n",
        "    return haralick\n",
        "# Color Histogram\n",
        "def fd_histogram(image, mask=None):\n",
        "    # convert the image to HSV color-space\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    # compute the color histogram\n",
        "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
        "    # normalize the histogram\n",
        "    cv2.normalize(hist, hist)\n",
        "    # return the histogram\n",
        "    return hist.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqdeXdMFmUPw"
      },
      "outputs": [],
      "source": [
        "# get the training labels\n",
        "train_path = \"/content/output/train\"\n",
        "train_labels = os.listdir(train_path)\n",
        "\n",
        "# sort the training labels\n",
        "train_labels.sort()\n",
        "print(train_labels)\n",
        "\n",
        "# empty lists to hold feature vectors and labels\n",
        "global_features = []\n",
        "labels          = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMgI9VlymUTL"
      },
      "outputs": [],
      "source": [
        "# loop over the training data sub-folders\n",
        "for nums, training_name in tqdm(enumerate(train_labels)):\n",
        "\n",
        "    # join the training data path and each species training folder\n",
        "    dir = os.path.join(train_path, training_name)\n",
        "\n",
        "    # get the current training label\n",
        "    current_label = training_name\n",
        "\n",
        "    # loop over the images in each sub-folder\n",
        "    for x in os.listdir(f\"{train_path}/{train_labels[nums]}\"):\n",
        "\n",
        "        # get the image file name\n",
        "        file = dir + \"/\" + x\n",
        "\n",
        "        # read the image and resize it to a fixed-size\n",
        "        image = cv2.imread(file)\n",
        "        image = cv2.resize(image, tuple((500,500)))\n",
        "\n",
        "        # Global Feature extraction\n",
        "        fv_hu_moments = fd_hu_moments(image)\n",
        "        fv_haralick   = fd_haralick(image)\n",
        "        fv_histogram  = fd_histogram(image)\n",
        "\n",
        "        # Concatenate / Combine Global Feature\n",
        "        global_feature = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n",
        "\n",
        "        # update the list of labels and feature vectors\n",
        "        labels.append(current_label)\n",
        "        global_features.append(global_feature)\n",
        "\n",
        "    print(\"[STATUS] processed folder: {}\".format(current_label))\n",
        "\n",
        "print(\"[STATUS] completed Global Feature Extraction...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU8p-O4hmUYC"
      },
      "outputs": [],
      "source": [
        "# get the overall feature vector size\n",
        "print(\"[STATUS] feature vector size {}\".format(np.array(global_features).shape))\n",
        "\n",
        "# get the overall training label size\n",
        "print(\"[STATUS] training Labels {}\".format(np.array(labels).shape))\n",
        "\n",
        "# encode the target labels\n",
        "targetNames = np.unique(labels)\n",
        "le          = LabelEncoder()\n",
        "target      = le.fit_transform(labels)\n",
        "print(\"[STATUS] training labels encoded...\")\n",
        "\n",
        "# scale features in the range (0-1)\n",
        "scaler            = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaled_features = scaler.fit_transform(global_features)\n",
        "print(\"[STATUS] feature vector normalized...\")\n",
        "\n",
        "print(\"[STATUS] target labels: {}\".format(target))\n",
        "print(\"[STATUS] target labels shape: {}\".format(target.shape))\n",
        "\n",
        "# save the feature vector using HDF5\n",
        "h5f_data = h5py.File(h5_data, 'w')\n",
        "h5f_data.create_dataset('dataset_1', data=np.array(rescaled_features))\n",
        "\n",
        "h5f_label = h5py.File(h5_labels, 'w')\n",
        "h5f_label.create_dataset('dataset_1', data=np.array(target))\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()\n",
        "\n",
        "print(\"[STATUS] end of training..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLCupvHB5pXw"
      },
      "outputs": [],
      "source": [
        "# tunable-parameters\n",
        "num_trees = 100\n",
        "test_size = 0.10\n",
        "seed      = 9\n",
        "train_path = \"/content/output/train\"\n",
        "test_path  = \"/content/output/val\"\n",
        "h5_data    = 'data.h5'\n",
        "h5_labels  = 'labels.h5'\n",
        "scoring    = \"accuracy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl7jlnF85pbn"
      },
      "outputs": [],
      "source": [
        "# get the training labels\n",
        "train_labels = os.listdir(train_path)\n",
        "\n",
        "# sort the training labels\n",
        "train_labels.sort()\n",
        "\n",
        "if not os.path.exists(test_path):\n",
        "    os.makedirs(test_path)\n",
        "\n",
        "# create all the machine learning models\n",
        "models = []\n",
        "models.append(('Logistic Regression', LogisticRegression(random_state=seed)))\n",
        "models.append(('K-Nearest Neighbors', KNeighborsClassifier()))\n",
        "models.append(('Decision Tree', DecisionTreeClassifier(random_state=seed)))\n",
        "models.append(('Random Forest', RandomForestClassifier(n_estimators=num_trees, random_state=seed)))\n",
        "models.append(('Support Vector Machine', SVC(random_state=seed)))\n",
        "\n",
        "# variables to hold the results and names\n",
        "results = []\n",
        "names   = []\n",
        "\n",
        "# import the feature vector and trained labels\n",
        "h5f_data  = h5py.File(h5_data, 'r')\n",
        "h5f_label = h5py.File(h5_labels, 'r')\n",
        "\n",
        "global_features_string = h5f_data['dataset_1']\n",
        "global_labels_string   = h5f_label['dataset_1']\n",
        "\n",
        "global_features = np.array(global_features_string)\n",
        "global_labels   = np.array(global_labels_string)\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()\n",
        "\n",
        "# verify the shape of the feature vector and labels\n",
        "print(\"[STATUS] features shape: {}\".format(global_features.shape))\n",
        "print(\"[STATUS] labels shape: {}\".format(global_labels.shape))\n",
        "\n",
        "print(\"[STATUS] training started...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhqWdnRM5phU"
      },
      "outputs": [],
      "source": [
        "# split the training and testing data\n",
        "(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(np.array(global_features),\n",
        "                                                                                          np.array(global_labels),\n",
        "                                                                                          test_size=test_size,\n",
        "                                                                                          random_state=seed)\n",
        "\n",
        "print(\"[STATUS] splitted train and test data...\")\n",
        "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
        "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
        "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
        "print(\"Test labels : {}\".format(testLabelsGlobal.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxzdwXjz6QTu"
      },
      "outputs": [],
      "source": [
        "# 10-fold cross validation\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=10, random_state=seed)\n",
        "    cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f\" % (name, cv_results.mean())\n",
        "    print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYkntzRv6Y11"
      },
      "outputs": [],
      "source": [
        "# boxplot algorithm comparison\n",
        "fig = plt.figure(figsize=(25,10))\n",
        "fig.suptitle('Machine Learning algorithm comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9CkuyyErVbX"
      },
      "outputs": [],
      "source": [
        "# Conclusion => Compare with 5 Models Above (Without LeNet5), \"Model Random Forest\" is the \"highest\" accuracy model in this datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMp7H4E7rWZO"
      },
      "source": [
        "## Create Test DataFrame => Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Let7QLDORfMA"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/LeNet_10.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPB_MKJhRoQm"
      },
      "outputs": [],
      "source": [
        "def pred_LeNet(path):\n",
        "  img = cv2.imread(path)\n",
        "  try:\n",
        "    img = img.reshape(-1,256,256,3)\n",
        "  except:\n",
        "    img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC).reshape(-1,256,256,3)\n",
        "  results = model.predict(img)\n",
        "  results = np.argmax(results,axis = 1)\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQMBzr5mpUVG"
      },
      "outputs": [],
      "source": [
        "path_file, label_file = [],[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxYqwMRRrGaK"
      },
      "outputs": [],
      "source": [
        "for x in os.listdir(\"/content/drive/MyDrive/data_img\"):\n",
        "  for y in os.listdir(\"/content/drive/MyDrive/data_img/\"+x):\n",
        "    path_file.append(\"/content/drive/MyDrive/data_img/\"+x+\"/\"+y)\n",
        "    label_file.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dBo02vdrecz"
      },
      "outputs": [],
      "source": [
        "data_ready = pd.DataFrame({\"Filename\":path_file,\n",
        "                           \"Label File\":label_file})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P17O8WBCt8EX"
      },
      "outputs": [],
      "source": [
        "f1,f2,f3 = [],[],[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZpMZs9nt0zT"
      },
      "outputs": [],
      "source": [
        "for x in tqdm(data_ready.Filename):\n",
        "  # read the image and resize it to a fixed-size\n",
        "  image = cv2.imread(x)\n",
        "  image = cv2.resize(image, tuple((500,500)))\n",
        "\n",
        "  # Global Feature extraction\n",
        "  fv_hu_moments = fd_hu_moments(image)\n",
        "  fv_haralick   = fd_haralick(image)\n",
        "  fv_histogram  = fd_histogram(image)\n",
        "\n",
        "  f1.append(fd_hu_moments(image).mean())\n",
        "  f2.append(fd_haralick(image).mean())\n",
        "  f3.append(fd_histogram(image).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNy9a96buRiU"
      },
      "outputs": [],
      "source": [
        "data_ready[\"Feature 1\"] = f1\n",
        "data_ready[\"Feature 2\"] = f2\n",
        "data_ready[\"Feature 3\"] = f3\n",
        "data_ready[\"Label File\"]= data_ready[\"Label File\"].replace({'Blight':0, 'Gray_Leaf_Spot':1, 'Common_Rust':2, 'Healthy':3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTfVppRtrpoC"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_ready.drop([\"Filename\",\"Label File\"], axis=1).values,\n",
        "                                                    data_ready[\"Label File\"].values,\n",
        "                                                    test_size=0.3,\n",
        "                                                    shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnfgUtdMsSfZ"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icF1_WpTwvEE"
      },
      "outputs": [],
      "source": [
        "# fit model\n",
        "Logreg = LogisticRegression(C=float(10**5), class_weight=None, dual=False, fit_intercept=True,\n",
        "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
        "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
        "                   random_state=9, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                   warm_start=False).fit(X_train, y_train)\n",
        "Knn =  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
        "                     weights='uniform').fit(X_train, y_train)\n",
        "DCT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
        "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                       random_state=9, splitter='best').fit(X_train, y_train)\n",
        "RFC = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=None, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                       n_jobs=None, oob_score=False, random_state=9, verbose=0,\n",
        "                       warm_start=False).fit(X_train, y_train)\n",
        "SVM =SVC(C=10**2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
        "    max_iter=-1, probability=False, random_state=9, shrinking=True, tol=0.001,\n",
        "    verbose=False).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWfyYzc949Ku"
      },
      "outputs": [],
      "source": [
        "# evaluate each models (original) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDls56Md5OWD"
      },
      "outputs": [],
      "source": [
        "logreg_pred = Logreg.predict(X_test)\n",
        "results = confusion_matrix(y_test, logreg_pred)\n",
        "print ('Confusion Matrix :\\n')\n",
        "print(results)\n",
        "print ('\\nAccuracy Score is',accuracy_score(y_test, logreg_pred))\n",
        "print ('\\nClassification Report : \\n')\n",
        "print (classification_report(y_test, logreg_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-tiN-yx7Eqz"
      },
      "outputs": [],
      "source": [
        "Knn_pred = Knn.predict(X_test)\n",
        "results = confusion_matrix(y_test, Knn_pred)\n",
        "print ('Confusion Matrix :\\n')\n",
        "print(results)\n",
        "print ('\\nAccuracy Score is',accuracy_score(y_test, Knn_pred))\n",
        "print ('\\nClassification Report : \\n')\n",
        "print (classification_report(y_test, Knn_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U3sYC9G7SHt"
      },
      "outputs": [],
      "source": [
        "DCT_pred = DCT.predict(X_test)\n",
        "results = confusion_matrix(y_test, DCT_pred)\n",
        "print ('Confusion Matrix :\\n')\n",
        "print(results)\n",
        "print ('\\nAccuracy Score is',accuracy_score(y_test, DCT_pred))\n",
        "print ('\\nClassification Report : \\n')\n",
        "print (classification_report(y_test, DCT_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6BY6vL-7ic-"
      },
      "outputs": [],
      "source": [
        "RFC_pred = RFC.predict(X_test)\n",
        "results = confusion_matrix(y_test, RFC_pred)\n",
        "print ('Confusion Matrix :\\n')\n",
        "print(results)\n",
        "print ('\\nAccuracy Score is',accuracy_score(y_test, RFC_pred))\n",
        "print ('\\nClassification Report : \\n')\n",
        "print (classification_report(y_test, RFC_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTyamOAI7wXI"
      },
      "outputs": [],
      "source": [
        "SVM_pred = SVM.predict(X_test)\n",
        "results = confusion_matrix(y_test, SVM_pred)\n",
        "print ('Confusion Matrix :\\n')\n",
        "print(results)\n",
        "print ('\\nAccuracy Score is',accuracy_score(y_test, SVM_pred))\n",
        "print ('\\nClassification Report : \\n')\n",
        "print (classification_report(y_test, SVM_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw9LBAYw_VWE"
      },
      "outputs": [],
      "source": [
        "log = Logreg.predict(data_ready.drop([\"Filename\",\"Label File\"], axis=1))\n",
        "knn = Knn.predict(data_ready.drop([\"Filename\",\"Label File\"], axis=1))\n",
        "rfc = RFC.predict(data_ready.drop([\"Filename\",\"Label File\"], axis=1))\n",
        "dct = DCT.predict(data_ready.drop([\"Filename\",\"Label File\"], axis=1))\n",
        "svm = SVM.predict(data_ready.drop([\"Filename\",\"Label File\"], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15CPDSbZ8EUg"
      },
      "outputs": [],
      "source": [
        "data_ready[\"Logistic Regression\"] = log\n",
        "data_ready[\"K-Nearest Neighbour\"] = knn\n",
        "data_ready[\"Random Forest\"] = rfc\n",
        "data_ready[\"Decision Tree\"] = dct\n",
        "data_ready[\"Support Vector Machine\"] = svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi9bXWX7-pxv"
      },
      "outputs": [],
      "source": [
        "cnn = [pred_LeNet(x) for x in data_ready[\"Filename\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpVpYbPf_-PH"
      },
      "outputs": [],
      "source": [
        "data_ready[\"L-Net5\"] = cnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MALklrn5CXAZ"
      },
      "outputs": [],
      "source": [
        "data_ready.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT-eSUVJCYhB"
      },
      "outputs": [],
      "source": [
        "submit = data_ready.drop([\"Filename\",\"Label File\", \"Feature 1\", \"Feature 2\", \"Feature 3\"], axis=1)\n",
        "submit[\"FIlename\"] = df.FileName"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W6D9P0OCyE6"
      },
      "outputs": [],
      "source": [
        "submit.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sxDi6pyC1n2"
      },
      "outputs": [],
      "source": [
        "submit.to_csv(\"Submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Predict Corn DIsease.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
